> [자바로 배우는 핵심 자료구조와 알고리즘](http://www.yes24.com/Product/Goods/61198657)을 참고해 정리한 내용입니다.
# 6장 트리 순회
## 6.1 검색 엔진
- **웹 검색 엔진(Web search engine)**: 일련의 검색어를 받아 그와 관련된 웹 페이지의 목록을 반환한다.
- 검색 엔진의 필수 요소
	- **크롤링(Crawling)**: 웹 페이지를 다운로드한 후, 파싱해 텍스트와 다른 페이지로의 링크를 추출하는 프로그램
	- **인덱싱(indexing)**: 검색어를 조회하고 해당 검색어를 포함한 페이지를 찾는 데 필요한 자료구조
	- **검색(retrieval)**: 인덱스에서 결과를 수집하고 가장 관련된 페이지를 식별하는 방법
- 실습할 것: 크롤러를 이용해 위키피디아 페이지를 읽고 첫 번째 링크를 찾고 다른 페이지로 링크를  따라가기를 반복하는 크롤러를 만들자. 이 반복되는 과정을 통해 [위키피디아 철학 문서](https://en.wikipedia.org/wiki/Philosophy)로 도달해보자.

## 6.2 HTML 파싱하기
- 웹 페이지를 다운로드할 때 그 내용은 하이퍼 텍스트 마크업 언어(HyperText Markup Language, HTML)로 작성되어 있다.
- HTML 페이지를 다운로드하고 파싱한 후, 본문과 링크를 추출해야 한다. 이를 위해 오픈소스 자바 라이브러리인 [jsoup](https://jsoup.org/)을 사용한다.
- HTML 파싱의 결과는 문서 객체 모델 트리 구조이다. 트리의 각 노드는 텍스트와 태그, 다른 문서 요소를 나타낸다.
	- 문서 객체 모델(Document Object Model, DOM): 본문과 태그 같은 문서 요소를 담고 있다.
- 각 노드는 자식 노드에 대한 링크를 포함한다. 

## 6.3 jsoup 사용하기
- jsoup 라이브러리를 이용해 웹 페이지를 다운로드해 파싱하고, DOM 트리를 탐색해보자.

- **WikiNodeExample.java** 파일 참고
```java
String url = "https://en.wikipedia.org/wiki/Java_(programming_language)";

// 문서를 다운로드하고 파싱하기
Connection conn = Jsoup.connect(url);
Document doc = conn.get();

// 내용을 선택하고 단락 추출하기
Element content = doc.getElementById("mw-content-text");
Elements paragraphs = content.select("p");
```
